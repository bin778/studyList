{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc8043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6748b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=torch.FloatTensor([[.1,.2,.3],[.4,.5,.6],[.7,.8,.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d38d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2316, 0.0607, 0.2361],\n",
      "        [0.3857, 0.5836, 0.8604],\n",
      "        [0.3771, 0.0152, 0.0278]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand_like(target)\n",
    "x.requires_grad=True\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625add46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1774, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=F.mse_loss(x,target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825f8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Loss: 6.4923e-02\n",
      "tensor([[0.1796, 0.1157, 0.2614],\n",
      "        [0.3914, 0.5505, 0.7575],\n",
      "        [0.5047, 0.3253, 0.3724]], requires_grad=True)\n",
      "2-th Loss: 3.9274e-02\n",
      "tensor([[0.1619, 0.1344, 0.2699],\n",
      "        [0.3933, 0.5393, 0.7225],\n",
      "        [0.5481, 0.4308, 0.4896]], requires_grad=True)\n",
      "3-th Loss: 2.3759e-02\n",
      "tensor([[0.1481, 0.1490, 0.2766],\n",
      "        [0.3948, 0.5306, 0.6953],\n",
      "        [0.5818, 0.5128, 0.5808]], requires_grad=True)\n",
      "4-th Loss: 1.4372e-02\n",
      "tensor([[0.1374, 0.1603, 0.2818],\n",
      "        [0.3959, 0.5238, 0.6741],\n",
      "        [0.6081, 0.5766, 0.6517]], requires_grad=True)\n",
      "5-th Loss: 8.6944e-03\n",
      "tensor([[0.1291, 0.1692, 0.2859],\n",
      "        [0.3968, 0.5185, 0.6576],\n",
      "        [0.6285, 0.6263, 0.7069]], requires_grad=True)\n",
      "6-th Loss: 5.2596e-03\n",
      "tensor([[0.1227, 0.1760, 0.2890],\n",
      "        [0.3975, 0.5144, 0.6448],\n",
      "        [0.6444, 0.6649, 0.7498]], requires_grad=True)\n",
      "7-th Loss: 3.1817e-03\n",
      "tensor([[0.1176, 0.1813, 0.2914],\n",
      "        [0.3981, 0.5112, 0.6349],\n",
      "        [0.6568, 0.6949, 0.7832]], requires_grad=True)\n",
      "8-th Loss: 1.9248e-03\n",
      "tensor([[0.1137, 0.1855, 0.2933],\n",
      "        [0.3985, 0.5087, 0.6271],\n",
      "        [0.6664, 0.7183, 0.8091]], requires_grad=True)\n",
      "9-th Loss: 1.1644e-03\n",
      "tensor([[0.1107, 0.1887, 0.2948],\n",
      "        [0.3988, 0.5068, 0.6211],\n",
      "        [0.6738, 0.7364, 0.8293]], requires_grad=True)\n",
      "10-th Loss: 7.0436e-04\n",
      "tensor([[0.1083, 0.1912, 0.2960],\n",
      "        [0.3991, 0.5053, 0.6164],\n",
      "        [0.6797, 0.7506, 0.8450]], requires_grad=True)\n",
      "11-th Loss: 4.2610e-04\n",
      "tensor([[0.1064, 0.1932, 0.2969],\n",
      "        [0.3993, 0.5041, 0.6128],\n",
      "        [0.6842, 0.7615, 0.8573]], requires_grad=True)\n",
      "12-th Loss: 2.5776e-04\n",
      "tensor([[0.1050, 0.1947, 0.2976],\n",
      "        [0.3995, 0.5032, 0.6099],\n",
      "        [0.6877, 0.7701, 0.8668]], requires_grad=True)\n",
      "13-th Loss: 1.5593e-04\n",
      "tensor([[0.1039, 0.1959, 0.2981],\n",
      "        [0.3996, 0.5025, 0.6077],\n",
      "        [0.6904, 0.7767, 0.8741]], requires_grad=True)\n",
      "14-th Loss: 9.4328e-05\n",
      "tensor([[0.1030, 0.1968, 0.2985],\n",
      "        [0.3997, 0.5019, 0.6060],\n",
      "        [0.6926, 0.7819, 0.8799]], requires_grad=True)\n",
      "15-th Loss: 5.7063e-05\n",
      "tensor([[0.1024, 0.1975, 0.2989],\n",
      "        [0.3997, 0.5015, 0.6047],\n",
      "        [0.6942, 0.7859, 0.8844]], requires_grad=True)\n",
      "16-th Loss: 3.4520e-05\n",
      "tensor([[0.1018, 0.1981, 0.2991],\n",
      "        [0.3998, 0.5012, 0.6036],\n",
      "        [0.6955, 0.7891, 0.8878]], requires_grad=True)\n",
      "17-th Loss: 2.0882e-05\n",
      "tensor([[0.1014, 0.1985, 0.2993],\n",
      "        [0.3998, 0.5009, 0.6028],\n",
      "        [0.6965, 0.7915, 0.8905]], requires_grad=True)\n",
      "18-th Loss: 1.2632e-05\n",
      "tensor([[0.1011, 0.1988, 0.2995],\n",
      "        [0.3999, 0.5007, 0.6022],\n",
      "        [0.6973, 0.7934, 0.8926]], requires_grad=True)\n",
      "19-th Loss: 7.6419e-06\n",
      "tensor([[0.1009, 0.1991, 0.2996],\n",
      "        [0.3999, 0.5005, 0.6017],\n",
      "        [0.6979, 0.7948, 0.8943]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "threshold=1e-5\n",
    "learning_rate=1.\n",
    "iter_cnt=0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt+=1\n",
    "    loss.backward()\n",
    "    \n",
    "    x=x-learning_rate*x.grad\n",
    "    \n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "    \n",
    "    loss=F.mse_loss(x,target)\n",
    "    \n",
    "    print('%d-th Loss: %.4e' %(iter_cnt,loss))\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
