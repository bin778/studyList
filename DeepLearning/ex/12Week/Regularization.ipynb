{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c2de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156c3ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([60000])\n",
      "input_size: 784, output_size: 10\n"
     ]
    }
   ],
   "source": [
    "train=datasets.MNIST(\n",
    "    '../data',train=True,download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "test=datasets.MNIST(\n",
    "    '../data',train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "x=train.data.float()/255.\n",
    "y=train.targets\n",
    "\n",
    "x=x.view(x.size(0),-1)\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "input_size=x.size(-1)\n",
    "output_size=int(max(y))+1\n",
    "\n",
    "print('input_size: %d, output_size: %d' % (input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dd4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 48000 / Valid 12000 / Test 10000 samples.\n",
      "torch.Size([48000, 784]) torch.Size([48000])\n",
      "torch.Size([12000, 784]) torch.Size([12000])\n",
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# Train / Valid ratio\n",
    "ratios=[.8,.2]\n",
    "\n",
    "train_cnt=int(x.size(0)*ratios[0])\n",
    "valid_cnt=int(x.size(0)*ratios[1])\n",
    "test_cnt=len(test.data)\n",
    "cnts=[train_cnt,valid_cnt]\n",
    "\n",
    "print(\"Train %d / Valid %d / Test %d samples.\" % (train_cnt,valid_cnt,test_cnt))\n",
    "\n",
    "indices=torch.randperm(x.size(0))\n",
    "\n",
    "x=torch.index_select(x,dim=0,index=indices)\n",
    "y=torch.index_select(y,dim=0,index=indices)\n",
    "\n",
    "x=list(x.split(cnts,dim=0))\n",
    "y=list(y.split(cnts,dim=0))\n",
    "\n",
    "x+=[(test.data.float()/255.).view(test_cnt,-1)]\n",
    "y+=[test.targets]\n",
    "\n",
    "for x_i,y_i in zip(x,y):\n",
    "    print(x_i.size(),y_i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab10281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,input_size,output_size,use_batch_norm=True,dropout_p=.4):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size\n",
    "        self.use_batch_norm=use_batch_norm\n",
    "        self.dropout_p=dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        def get_regularizer(use_batch_norm,size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.block=nn.Sequential(\n",
    "            nn.Linear(input_size,output_size),\n",
    "            nn.LeakyReLU(),\n",
    "            get_regularizer(use_batch_norm,output_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=self.block(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1db257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size,use_batch_norm=True,dropout_p=.4):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            Block(input_size,500,use_batch_norm,dropout_p),\n",
    "            Block(500,400,use_batch_norm,dropout_p),\n",
    "            Block(400,300,use_batch_norm,dropout_p),\n",
    "            Block(300,200,use_batch_norm,dropout_p),\n",
    "            Block(200,100,use_batch_norm,dropout_p),\n",
    "            Block(100,50,use_batch_norm,dropout_p),\n",
    "            nn.Linear(50,output_size),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        y=self.layers(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9572ed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (layers): Sequential(\n",
      "    (0): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "        (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (7): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=MyModel(input_size,output_size,use_batch_norm=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd78ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())\n",
    "crit=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f72661",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "\n",
    "model=model.to(device)\n",
    "\n",
    "x=[x_i.to(device) for x_i in x]\n",
    "y=[y_i.to(device) for y_i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d86399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1000\n",
    "batch_size=256\n",
    "print_interval=10\n",
    "\n",
    "lowest_loss=np.inf\n",
    "best_model=None\n",
    "\n",
    "early_stop=50\n",
    "lowest_epoch=np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79927e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train loss=0.0238 valid_loss=0.0019 lowest_loss=0.0012\n",
      "Epoch 20: train loss=0.0140 valid_loss=0.0031 lowest_loss=0.0012\n",
      "Epoch 30: train loss=0.0062 valid_loss=0.0028 lowest_loss=0.0012\n",
      "Epoch 40: train loss=0.0048 valid_loss=0.0052 lowest_loss=0.0012\n",
      "Epoch 50: train loss=0.0045 valid_loss=0.0045 lowest_loss=0.0012\n",
      "There is no improvement during last 50 epochs.\n",
      "The best validation loss from epoch 9: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history,valid_history=[],[]\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    indices=torch.randperm(x[0].size(0)).to(device)\n",
    "    x_=torch.index_select(x[0],dim=0,index=indices)\n",
    "    y_=torch.index_select(y[0],dim=0,index=indices)\n",
    "    \n",
    "    x_=x_.split(batch_size,dim=0)\n",
    "    y_=y_.split(batch_size,dim=0)\n",
    "    \n",
    "    train_loss,valid_loss=0,0\n",
    "    y_hat=[]\n",
    "    \n",
    "    for x_i,y_i in zip(x_,y_):\n",
    "        y_hat_i=model(x_i)\n",
    "        loss=crit(y_hat_i,y_i.squeeze())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss+=float(loss)\n",
    "    \n",
    "    train_loss=train_loss/len(x_)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_=x[1].split(batch_size,dim=0)\n",
    "        y_=y[1].split(batch_size,dim=0)\n",
    "        \n",
    "        valid_loss=0\n",
    "        \n",
    "        for x_i,y_i in zip(x_,y_):\n",
    "            y_hat_i=model(x_i)\n",
    "            loss=crit(y_hat_i,y_i.squeeze())\n",
    "            \n",
    "            valid_loss=float(loss)\n",
    "            \n",
    "            y_hat+=[y_hat_i]\n",
    "    \n",
    "    valid_loss=valid_loss/len(x_)\n",
    "    \n",
    "    train_history+=[train_loss]\n",
    "    valid_history+=[valid_loss]\n",
    "    \n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print('Epoch %d: train loss=%.4f valid_loss=%.4f lowest_loss=%.4f' %\n",
    "(\n",
    "            i+1,\n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            lowest_loss,\n",
    "        ))\n",
    "    \n",
    "    if valid_loss<=lowest_loss:\n",
    "        lowest_loss=valid_loss\n",
    "        lowest_epoch=i\n",
    "        \n",
    "        best_model=deepcopy(model.state_dict())\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i + 1:\n",
    "            print(\"There is no improvement during last %d epochs.\" % early_stop)\n",
    "            break\n",
    "\n",
    "print(\"The best validation loss from epoch %d: %.4f\" %(lowest_epoch+1,lowest_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3efff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_from=0\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.grid(True)\n",
    "plt.title(\"Train / Valid Loss History\")\n",
    "plt.plot(\n",
    "    range(plot_from,len(train_history)),train_history[plot_from:],\n",
    "    range(plot_from,len(valid_history)),valid_history[plot_from:],\n",
    ")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33fc044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 7.2093e-02\n",
      "Test Accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "test_loss=0\n",
    "y_hat=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_=x[-1].split(batch_size,dim=0)\n",
    "    y_=y[-1].split(batch_size,dim=0)\n",
    "    \n",
    "    for x_i,y_i in zip(x_,y_):\n",
    "        y_hat_i=model(x_i)\n",
    "        loss=crit(y_hat_i,y_i.squeeze())\n",
    "        test_loss+=loss\n",
    "        \n",
    "        y_hat+=[y_hat_i]\n",
    "    \n",
    "test_loss=test_loss/len(x_)\n",
    "y_hat=torch.cat(y_hat,dim=0)\n",
    "\n",
    "print(\"Test loss: %.4e\" % test_loss)\n",
    "\n",
    "correct_cnt=(y[-1].squeeze()==torch.argmax(y_hat,dim=-1)).sum()\n",
    "total_cnt=float(y[-1].size(0))\n",
    "\n",
    "print(\"Test Accuracy: %.4f\" %(correct_cnt/total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540c8d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>877</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>955</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0  pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7  \\\n",
       "true_0     973       1       1       1       0       1       0       1   \n",
       "true_1       0    1132       0       1       0       0       1       0   \n",
       "true_2       3       2    1008       2       1       0       2       5   \n",
       "true_3       0       0       3     989       0       8       0       2   \n",
       "true_4       1       0       4       0     964       0       5       2   \n",
       "true_5       1       1       0       6       1     877       2       1   \n",
       "true_6       6       3       0       0       3       4     940       0   \n",
       "true_7       0       5       5       7       4       1       0    1003   \n",
       "true_8       2       2       1       6       0       1       1       1   \n",
       "true_9       1       2       0       3      16       4       0       4   \n",
       "\n",
       "        pred_8  pred_9  \n",
       "true_0       1       1  \n",
       "true_1       1       0  \n",
       "true_2       8       1  \n",
       "true_3       4       4  \n",
       "true_4       1       5  \n",
       "true_5       1       2  \n",
       "true_6       2       0  \n",
       "true_7       1       2  \n",
       "true_8     955       5  \n",
       "true_9       4     975  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y[-1].cpu(),torch.argmax(y_hat.cpu(),dim=-1)),\n",
    "               index=['true_%d' % i for i in range(10)],\n",
    "               columns=['pred_%d' % i for i in range(10)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
