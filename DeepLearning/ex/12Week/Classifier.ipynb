{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042d10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,input_size,output_size,use_batch_norm=True,dropout_p=.4):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size\n",
    "        self.use_batch_norm=use_batch_norm\n",
    "        self.dropout_p=dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        def get_regularizer(use_batch_norm,size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.block=nn.Sequential(\n",
    "            nn.Linear(input_size,output_size),\n",
    "            nn.LeakyReLU(),\n",
    "            get_regularizer(use_batch_norm,output_size),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y=self.block(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b334072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassfier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 hidden_sizes=[500,400,300,200,100],\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_p=.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(hidden_sizes) > 0, \"You need to specify hidden layers\"\n",
    "        \n",
    "        last_hidden_size=input_size\n",
    "        blocks=[]\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            block += [Block(\n",
    "                last_hidden_size,\n",
    "                hidden_size,\n",
    "                use_batch_norm,\n",
    "                dropout_p\n",
    "            )]\n",
    "            last_hidden_size=hidden_size\n",
    "        \n",
    "        self.layers=nn.Sequential(\n",
    "            *blocks,\n",
    "            nn.Linear(input_size,output_size),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y=self.layers(x)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
